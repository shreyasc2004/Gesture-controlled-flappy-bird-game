import tensorflow as tf
import pickle
import numpy as np
import os

class GestureInterpreter:
    def __init__(self, model_path='gesture_model.keras', encoder_path='label_encoder.pkl', scaler_path='scaler.pkl'):
        print("Initializing Gesture Interpreter...")
        
        # Check for all required files
        if not all(os.path.exists(p) for p in [model_path, encoder_path, scaler_path]):
            print("="*50)
            print("ERROR: Model files not found!")
            print(f"Could not find '{model_path}', '{encoder_path}', or '{scaler_path}'.")
            print("Please run the following script first:")
            print("1. py -3.10 ModelTrainer.py")
            print("="*50)
            print("Exiting. Please train the model first.")
            exit()
            
        try:
            # Load the trained MLP model
            self.model = tf.keras.models.load_model(model_path)
            
            # Load the label encoder
            with open(encoder_path, 'rb') as f:
                self.label_encoder = pickle.load(f)
                
            # ** Load the scaler (this is the critical fix) **
            with open(scaler_path, 'rb') as f:
                self.scaler = pickle.load(f)
                
            self.classes = self.label_encoder.classes_
            print(f"Successfully loaded model, encoder, and scaler.")
            print(f"Ready to classify gestures: {self.classes}")

        except Exception as e:
            print(f"Error loading files: {e}")
            print("Please ensure files are not corrupted and were generated by ModelTrainer.py")
            exit()

    def classify(self, landmarks):
        """
        Classifies a list of landmarks into a gesture.
        'landmarks' should be a flat list of 63 coordinates.
        """
        if landmarks is None or len(landmarks) != 63:
            return "NEUTRAL" # Default case if no hand is seen

        try:
            # 1. Convert landmarks to numpy array
            landmark_array = np.array(landmarks).reshape(1, -1)
            
            # 2. ** Scale the live data using the loaded scaler **
            landmark_scaled = self.scaler.transform(landmark_array)
            
            # 3. Predict using the scaled data
            # Added verbose=0 to prevent prediction logs from flooding the console
            prediction_probs = self.model.predict(landmark_scaled, verbose=0) 
            
            # 4. Get the class with the highest probability
            prediction_index = np.argmax(prediction_probs)
            confidence = np.max(prediction_probs)
            
            # 5. Confidence Threshold
            # Only return a gesture if the model is reasonably sure.
            if confidence > 0.6: # You can adjust this threshold (e.g., 0.7 or 0.8)
                predicted_gesture = self.label_encoder.classes_[prediction_index]
                return predicted_gesture
            else:
                return "NEUTRAL" # If not confident, default to neutral
                
        except Exception as e:
            print(f"Error during classification: {e}")
            return "NEUTRAL"

